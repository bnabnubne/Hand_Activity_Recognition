# Hand Motion Reconstruction & Synthetic Data Generation (Blender)

This repository provides a Blender-based pipeline for reconstructing real hand motion from the F-PHAB dataset and generating synthetic hand images under multiple camera viewpoints and appearance variations.

The project combines:
- Real hand motion data (F-PHAB skeleton annotations)  
- Inverse kinematicsâ€“driven hand rig in Blender  
- Synthetic data generation (multi-view, multi-skin, controlled lighting)  

All scripts are executed inside Blenderâ€™s Text Editor, using the provided .blend file.

---

## ğŸ“ Repository Structure

.
â”œâ”€â”€ hand_jan.blend                 
â”œâ”€â”€ RENDER.blend                   # Main working scene (preconfigured)
â”œâ”€â”€ Hand_pose_annotation_v1/       # F-PHAB dataset (skeleton.txt files)
â”œâ”€â”€ camera.py                      # Camera generation (base scene only)
â”œâ”€â”€ empty.py                       # IK empty creation (base scene only)
â”œâ”€â”€ load_skeleton.py               # Load F-PHAB skeleton motion
â”œâ”€â”€ render.py                      # Multi-camera, multi-skin rendering
â””â”€â”€ README.md


---

## ğŸ§© Pipeline Overview

The complete pipeline consists of the following logical steps:
1. Prepare a 3D hand rig with IK constraints in Blender  
2. Create empty objects as IK targets (TIP / PIP / MCP)  
3. Load real hand motion from F-PHAB (skeleton.txt)  
4. Generate multiple cameras around the hand  
5. Render synthetic hand images with different viewpoints and skin colors  

To avoid rig mismatch and animation transfer issues, all steps are performed inside a single Blender scene.

---

## ğŸ›  Requirements
- Blender 4.x (tested on Blender 4.2 LTS)  
- Apple Silicon with Metal support (for GPU rendering)  
- F-PHAB dataset (placed under Hand_pose_annotation_v1/)  

---

## â–¶ï¸ How to Run (Recommended Workflow)

âš ï¸ **Important**  
- Open `RENDER.blend` first  
- All scripts must be run via  
  `Blender â†’ Scripting â†’ Text Editor`  
- Do not run scripts externally via Python  

---

## âœ… Main Usage (Using RENDER.blend)

The provided `RENDER.blend` file is already preconfigured and includes:
- Hand armature (`Hand`)  
- Hand mesh (`HandMesh`)  
- IK constraints and joint limits  
- IK target empties (`*_TIP`, `*_PIP`, `*_MCP`)  
- Multi-view cameras (`Cam_*`)  
- Lighting and render settings  

ğŸ‘‰ For normal use, you only need to run **TWO scripts**.

---

### Step 1 â€“ Load Hand Motion from F-PHAB

Edit the dataset path in `load_skeleton.py`:
```python
FILE_PATH = ".../Subject_1/wash_sponge/1/skeleton.txt"
```
Then run: load_skeleton.py
What this script does:
â€¢	Reads skeleton.txt frame-by-frame
â€¢	Converts coordinates:
	â€¢	World â†’ Camera (Cam_0)
	â€¢	Camera â†’ Blender space
â€¢	Animates:
	â€¢	Wrist (armature object location)
	â€¢	MCP / PIP / TIP empties
	â€¢	Keeps IK constraints unchanged

âœ… Result:
	â€¢	The hand performs real motion from the dataset
	â€¢	Motion is temporally consistent

â¸»

### Step 2 â€“ Render Synthetic Data

Edit the configuration in render.py:
```python
action_label = "wash_sponge"
base_output_dir = "/path/to/render_output"
```python
Then run: render.py
What this script does:
â€¢	Enables Cycles GPU rendering (Metal)
â€¢	Iterates over:
	â€¢	All cameras (Cam_*)
	â€¢	Multiple skin materials (SkinA, SkinB, SkinC)
	â€¢	All animation frames
	â€¢	Renders images with transparent background

Output structure:
render_output/
â””â”€â”€ wash_sponge/
    â”œâ”€â”€ Cam_1/
    â”‚   â”œâ”€â”€ SkinA/
    â”‚   â”œâ”€â”€ SkinB/
    â”‚   â””â”€â”€ SkinC/
    â”œâ”€â”€ Cam_2/
    â””â”€â”€ ...

### ğŸ§° Base Scene Setup (Optional)

The following scripts are NOT required when using RENDER.blend.
They are only used when creating a new base scene from scratch.

empty.py
	â€¢	Creates IK target empties (*_TIP, *_PIP)
	â€¢	Places them at REST pose bone tail positions
	â€¢	Saves base positions for reset

camera.py
	â€¢	Generates multiple cameras (Cam_*)
	â€¢	Places cameras on a circular trajectory
	â€¢	Adds TRACK_TO constraint toward the hand

ğŸ‘‰ These scripts should be run once during base scene preparation.

â¸»

### ğŸ“· Camera Convention
	â€¢	Cam_0: Original first-person camera of the F-PHAB dataset
	â€¢	Cam_1 â€¦ Cam_N: Virtual cameras in Blender for synthetic data generation

Hand motion follows the dataset viewpoint (Cam_0), while rendering uses additional cameras.

â¸»

### ğŸ¯ Key Features
	â€¢	Skeleton-driven hand motion reconstruction
	â€¢	Inverse kinematics with bending plane stabilization
	â€¢	Multi-view and multi-skin synthetic data generation
	â€¢	Single-scene pipeline (no FBX import/export)
	â€¢	Suitable for hand pose and hand action recognition research

â¸»

### ğŸš§ Known Limitations
	â€¢	Finger overlap may occur in extreme poses
	â€¢	Anatomical accuracy depends on rigâ€“dataset alignment
	â€¢	No physical collision handling between fingers

â¸»

### ğŸ“Œ Notes
	â€¢	All scripts must be run inside Blender
	â€¢	Do not rerun camera.py or empty.py unless resetting the scene
	â€¢	Ensure object names match the scripts (Hand, HandMesh, Cam_*)